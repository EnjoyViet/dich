<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ë‹¤êµ­ì–´ AI ì‹¤ì‹œê°„ í†µì—­ (ë¸Œë¼ìš°ì €)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { background:#0b0b0b; color:#e6eef8; font-family:Inter,ui-sans-serif; }
    .card { background: #111214; border-radius:12px; padding:14px; border:1px solid rgba(255,255,255,0.04); }
    .speaker-box { border-radius:12px; padding:12px; min-height:120px; position:relative; }
    .btn { padding:10px 14px; border-radius:999px; font-weight:600; cursor:pointer; }
    .mic-btn { width:160px; height:60px; font-size:18px; border-radius:12px; }
    .listening { box-shadow: 0 0 18px rgba(59,130,246,0.6); transform:scale(1.02); }
  </style>
</head>
<body class="p-6 flex justify-center">

  <div class="w-full max-w-2xl space-y-5">
    <!-- ìƒë‹¨ ì–¸ì–´ ì„ íƒ -->
    <div class="card flex gap-4 items-center justify-between">
      <div class="w-1/2">
        <label class="text-sm text-gray-300">ë‚˜ì˜ ì–¸ì–´ (My Language)</label>
        <select id="selectL1" class="w-full mt-2 p-2 rounded bg-[#0f1720] text-white">
          <option value="ko-KR">í•œêµ­ì–´ (Korean)</option>
          <option value="vi-VN">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</option>
          <option value="en-US">ì˜ì–´ (English)</option>
          <option value="zh-CN">ì¤‘êµ­ì–´ (Chinese)</option>
          <option value="ja-JP">ì¼ë³¸ì–´ (Japanese)</option>
        </select>
      </div>

      <div class="w-1/2">
        <label class="text-sm text-gray-300">ìƒëŒ€ë°© ì–¸ì–´ (Their Language)</label>
        <select id="selectL2" class="w-full mt-2 p-2 rounded bg-[#0f1720] text-white">
          <option value="vi-VN">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</option>
          <option value="ko-KR">í•œêµ­ì–´ (Korean)</option>
          <option value="en-US">ì˜ì–´ (English)</option>
          <option value="zh-CN">ì¤‘êµ­ì–´ (Chinese)</option>
          <option value="ja-JP">ì¼ë³¸ì–´ (Japanese)</option>
        </select>
      </div>
    </div>

    <!-- L1 ë°•ìŠ¤ (íŒŒë‘ ê³„ì—´) -->
    <div class="card">
      <div class="flex items-center justify-between mb-2">
        <div class="text-sm text-blue-300 font-bold">ğŸ™ <span id="labelL1">í•œêµ­ì–´ (Korean)</span> í™”ì</div>
      </div>
      <div class="speaker-box" style="background:#071028; border:1px solid rgba(59,130,246,0.12);">
        <div id="L1Text" class="whitespace-pre-wrap text-white min-h-[80px]">ë²ˆì—­ëœ ìƒëŒ€ë°© ì–¸ì–´ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</div>
        <button id="btnTTSL1" title="ì´ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸°" class="btn absolute right-3 bottom-3 bg-blue-600 text-white">ğŸ”Š ìŒì„±</button>
      </div>
    </div>

    <!-- L2 ë°•ìŠ¤ (ë¹¨ê°• ê³„ì—´) -->
    <div class="card">
      <div class="flex items-center justify-between mb-2">
        <div class="text-sm text-red-300 font-bold">ğŸ™ <span id="labelL2">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</span> í™”ì</div>
      </div>
      <div class="speaker-box" style="background:#120a0c; border:1px solid rgba(239,68,68,0.08);">
        <div id="L2Text" class="whitespace-pre-wrap text-white min-h-[80px]">í•œêµ­ì–´ (Korean)ë¡œ ë²ˆì—­ëœ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</div>
        <button id="btnTTSL2" title="ì´ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸°" class="btn absolute right-3 bottom-3 bg-red-600 text-white">ğŸ”Š ìŒì„±</button>
      </div>
    </div>

    <!-- ì¤‘ì•™ ìŒì„± ì…ë ¥ ë²„íŠ¼ -->
    <div class="flex justify-center">
      <button id="micMain" class="mic-btn bg-teal-300 text-black font-bold">ìŒì„± ì…ë ¥</button>
    </div>

    <!-- ë¡œê·¸/ìƒíƒœ -->
    <div class="card text-sm text-gray-300">
      <div id="status">ì¤€ë¹„ ì™„ë£Œ. ë…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ 'ìŒì„± ì…ë ¥' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.</div>
      <div id="chatHistory" class="mt-2 max-h-36 overflow-auto text-xs text-gray-400"></div>
    </div>
    <div class="text-xs text-gray-500">âš ï¸ ì£¼ì˜: ë¸Œë¼ìš°ì €ì—ì„œ API Keyë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì€ ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤. ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ì„œë²„ í”„ë¡ì‹œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.</div>
  </div>

<script>
/*
  ì™„ì„±ëœ interpreter.html (ì˜µì…˜ A: Gemini + Google Speech-to-Text ì‚¬ìš© ì˜ˆì‹œ)
  ì‚¬ìš© ì „:
    1) API_KEY ë³€ìˆ˜ì— ìœ íš¨í•œ Google Cloud API Key ì‚½ì… (Speech-to-Text + Generative API ì‚¬ìš© ê¶Œí•œ)
    2) ë°°í¬ìš©(ìš´ì˜)ì—ì„œëŠ” ë¸Œë¼ìš°ì €ì— API Keyë¥¼ ì§ì ‘ ë‘ì§€ ë§ê³ , ì„œë²„ í”„ë¡ì‹œ(í† í° êµí™˜) ì‚¬ìš© ê¶Œì¥
*/

const API_KEY = "AIzaSyD62j5LrOBDu0efSqvKvZ_bOaTu599FqRg"; // <<--- ì—¬ê¸°ì— í‚¤ë¥¼ ë„£ìœ¼ì„¸ìš” (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
const SPEECH_RECOGNIZE_URL = `https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}`;
const GEMINI_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${API_KEY}`; // ë²ˆì—­ìš© ì˜ˆì‹œ

// UI elements
const selectL1 = document.getElementById('selectL1');
const selectL2 = document.getElementById('selectL2');
const labelL1 = document.getElementById('labelL1');
const labelL2 = document.getElementById('labelL2');
const L1Text = document.getElementById('L1Text');
const L2Text = document.getElementById('L2Text');
const btnTTSL1 = document.getElementById('btnTTSL1');
const btnTTSL2 = document.getElementById('btnTTSL2');
const micMain = document.getElementById('micMain');
const status = document.getElementById('status');
const chatHistory = document.getElementById('chatHistory');

let mediaRecorder = null;
let recordedChunks = [];
let isRecording = false;

// ì–¸ì–´ ë§¤í•‘ (ê°„ë‹¨í•œ í‘œì‹œìš©)
const LANG_MAP = {
  'ko-KR': 'í•œêµ­ì–´ (Korean)',
  'vi-VN': 'ë² íŠ¸ë‚¨ì–´ (Vietnamese)',
  'en-US': 'ì˜ì–´ (English)',
  'zh-CN': 'ì¤‘êµ­ì–´ (Chinese)',
  'ja-JP': 'ì¼ë³¸ì–´ (Japanese)'
};

// ìë™ ê°ì§€ ëŒ€ìƒ ì–¸ì–´ ì½”ë“œë¥¼ Speech-to-Textì— ì „ë‹¬ (Google STTì˜ alternativeLanguageCodes ì‚¬ìš©)
const AUTO_LANGS = ['ko-KR','vi-VN','en-US','zh-CN','ja-JP'];

// ì´ˆê¸° UI ì—…ë°ì´íŠ¸
function updateLabels() {
  labelL1.textContent = LANG_MAP[selectL1.value] || selectL1.value;
  labelL2.textContent = LANG_MAP[selectL2.value] || selectL2.value;
}
updateLabels();
selectL1.addEventListener('change', updateLabels);
selectL2.addEventListener('change', updateLabels);

// ==================== MediaRecorder ë…¹ìŒ ì œì–´ ====================
async function startRecording() {
  recordedChunks = [];
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert('ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì‹  ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.');
    return;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=opus' });

    mediaRecorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) recordedChunks.push(e.data);
    };

    mediaRecorder.onstart = () => {
      isRecording = true;
      micMain.classList.add('listening');
      micMain.textContent = 'ë…¹ìŒ ì¤‘... (ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì¢…ë£Œ)';
      status.textContent = 'ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”.';
    };

    mediaRecorder.onstop = async () => {
      isRecording = false;
      micMain.classList.remove('listening');
      micMain.textContent = 'ìŒì„± ì…ë ¥';
      status.textContent = 'ë…¹ìŒ ì¢…ë£Œ. ìŒì„± ì¸ì‹ ì¤‘...';

      // Blob ìƒì„±
      const blob = new Blob(recordedChunks, { type: recordedChunks[0]?.type || 'audio/webm' });
      await processRecordedAudio(blob);
    };

    mediaRecorder.start();
  } catch (err) {
    console.error(err);
    alert('ë§ˆì´í¬ ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
}

function stopRecording() {
  if (mediaRecorder && isRecording) {
    mediaRecorder.stop();
    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ (ê¶Œí•œ í•´ì œ)
    if (mediaRecorder.stream) {
      mediaRecorder.stream.getTracks().forEach(t => t.stop());
    }
  }
}

// í† ê¸€ ë²„íŠ¼ ë™ì‘
micMain.addEventListener('click', () => {
  if (!API_KEY || API_KEY.startsWith('REPLACE')) {
    alert('API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”. (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© - ë¸Œë¼ìš°ì €ì— í‚¤ë¥¼ ë…¸ì¶œí•˜ëŠ” ê²ƒì€ ë³´ì•ˆìƒ ìœ„í—˜í•©ë‹ˆë‹¤.)');
    return;
  }
  if (!isRecording) {
    startRecording();
  } else {
    stopRecording();
  }
});

// ==================== ì˜¤ë””ì˜¤ -> STT -> ë²ˆì—­ -> TTS íë¦„ ====================

/*
  processRecordedAudio(blob)
    1) blob -> base64
    2) Google Speech-to-Text REST í˜¸ì¶œ (recognize)
       - config: encoding, sampleRateHertz (optional), languageCode (primary) + alternativeLanguageCodes
       - response: results[0].alternatives[0].transcript
       - ì¼ë¶€ ì‘ë‹µì—ì„œ 'languageCode'ë¥¼ ë°˜í™˜í•˜ë©´ ìë™ ì–¸ì–´ ê°ì§€ ê²°ê³¼ë¡œ ì‚¬ìš©
    3) ë²ˆì—­: Gemini(ë˜ëŠ” ë‹¤ë¥¸ ë²ˆì—­ ì—”ì§„)ë¡œ ë²ˆì—­ ìš”ì²­ (source ìë™ê°ì§€ í›„ targetì€ selectL1/selectL2 ê´€ê³„ì— ë”°ë¼ ê²°ì •)
    4) ê²°ê³¼ í‘œì‹œ ë° TTS ì¬ìƒ
*/

async function blobToBase64(blob) {
  return new Promise((res, rej) => {
    const reader = new FileReader();
    reader.onloadend = () => res(reader.result.split(',')[1]); // base64 string (without prefix)
    reader.onerror = rej;
    reader.readAsDataURL(blob);
  });
}

function appendChat(role, lang, text) {
  const t = document.createElement('div');
  t.className = 'p-2 my-1';
  t.innerHTML = `<strong>${role} [${lang}]:</strong> ${text}`;
  chatHistory.appendChild(t);
  chatHistory.scrollTop = chatHistory.scrollHeight;
}

// STT: Google Speech-to-Text REST (synchronous recognize).
async function recognizeSpeechWithGoogle(base64Audio, mimeType) {
  // NOTE: Google REST 'speech:recognize' expects "audio": {content: base64}, and "config" describing encoding/sampleRate...
  // For best results, convert to LINEAR16 16kHz PCM on server side. Here we attempt with webm/opus and hope Google's auto-detection works.
  const payload = {
    config: {
      encoding: "WEBM_OPUS",        // best-effort - many browsers produce webm/opus
      sampleRateHertz: 48000,      // typical for browsers; Google may accept
      // Optional: specify primary language and alternative languages for auto-detection
      languageCode: "en-US",       // primary (used if ambiguous) - but we also provide alternatives
      alternativeLanguageCodes: AUTO_LANGS // allow auto detection among these
    },
    audio: {
      content: base64Audio
    }
  };

  const resp = await fetch(SPEECH_RECOGNIZE_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(payload)
  });

  if (!resp.ok) {
    const body = await resp.text();
    throw new Error(`Speech-to-Text HTTP ${resp.status}: ${body}`);
  }
  const json = await resp.json();
  return json;
}

// ë²ˆì—­(ë° ì–¸ì–´ ê°ì§€) - Gemini ì‚¬ìš© ì˜ˆì‹œ
async function translateWithGemini(text, fromLabel, targetLangCode) {
  // system prompt: ì „ë¬¸ ë™ì‹œí†µì—­ì‚¬ ì—­í• 
  const systemPrompt = `You are a professional translator. Detect the input language and translate it naturally into ${LANG_MAP[targetLangCode] || targetLangCode}. Only return the translated text, nothing else.`;
  const payload = {
    contents: [
      { role: "user", parts: [{ text: systemPrompt }] },
      { role: "user", parts: [{ text: `Translate this text into ${LANG_MAP[targetLangCode] || targetLangCode}: "${text}"` }] }
    ],
    config: { temperature: 0.1, topK: 1, topP: 0.9 }
  };

  const resp = await fetch(GEMINI_API_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(payload)
  });

  if (!resp.ok) {
    const b = await resp.text();
    throw new Error(`Gemini HTTP ${resp.status}: ${b}`);
  }
  const rjson = await resp.json();
  const translation = rjson?.candidates?.[0]?.content?.parts?.[0]?.text?.trim();
  // Note: Gemini might not return explicit detected language â€” STT response may contain language.
  return translation || '';
}

// ì–¸ì–´ ì½”ë“œì—ì„œ ì½ê¸°ìš© ì–¸ì–´(ìŒì„±í•©ì„± lang) ê²°ì •
function ttsLangFor(code) {
  // For browser speechSynthesis, use short code like 'ko-KR', 'vi-VN', etc.
  return code;
}

// ì‹¤ì œ ì²˜ë¦¬
async function processRecordedAudio(blob) {
  try {
    status.textContent = 'ì˜¤ë””ì˜¤ ì¸ì½”ë”© ì¤‘...';
    const base64 = await blobToBase64(blob);
    status.textContent = 'ìŒì„± ì¸ì‹ ìš”ì²­ ì¤‘... (Google Speech-to-Text)';
    const sttResp = await recognizeSpeechWithGoogle(base64, blob.type);

    // sttResp êµ¬ì¡° ì˜ˆ: { results: [{ alternatives: [{ transcript: "...", confidence: 0.9 }], languageCode: "vi-VN" }], ... }
    let transcript = '';
    let detectedLang = null;

    if (sttResp.results && sttResp.results.length) {
      // concatenate results
      transcript = sttResp.results.map(r => (r.alternatives && r.alternatives[0] && r.alternatives[0].transcript) ? r.alternatives[0].transcript : '').join(' ').trim();
      // Google may provide languageCode on top-level result or on recognitionConfig
      detectedLang = (sttResp.results[0] && sttResp.results[0].languageCode) || sttResp.languageCode || null;
    }

    if (!transcript) {
      status.textContent = 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      appendChat('System','', 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ.');
      return;
    }

    appendChat('User (ASR)', detectedLang || 'und', transcript);
    status.textContent = `ê°ì§€ëœ ì–¸ì–´: ${detectedLang || 'ìë™ ê°ì§€ ë¶ˆê°€'}. ë²ˆì—­ ì¤‘...`;

    // ë²ˆì—­: ë§Œì•½ detectedLang === selectL1, ë²ˆì—­ ëŒ€ìƒì€ L2, ë°˜ëŒ€ë©´ L1
    const selL1 = selectL1.value;
    const selL2 = selectL2.value;

    // Determine translation direction:
    // If detectedLang is one of our L1/L2 codes, use the other as target. Otherwise use selected L2 as default target.
    let targetLangCode = selL2;
    if (detectedLang) {
      const d = detectedLang.split('-')[0]; // e.g., "vi" from "vi-VN"
      const s1 = selL1.split('-')[0], s2 = selL2.split('-')[0];
      if (d === s1) targetLangCode = selL2;
      else if (d === s2) targetLangCode = selL1;
      else targetLangCode = selL2; // default: translate to ìƒëŒ€ë°© ì–¸ì–´
    }

    // Call Gemini to translate (Gemini does detection+translation prompt)
    const translated = await translateWithGemini(transcript, detectedLang || 'unknown', targetLangCode);

    // Update UI: write source and translation into appropriate boxes
    // If detectedLang corresponds to L1, then put original in L1 box and translated in L2 box.
    // Otherwise assume original belongs to detectedLang side.
    const detectedShort = detectedLang ? detectedLang.split('-')[0] : 'und';
    const s1Short = selL1.split('-')[0], s2Short = selL2.split('-')[0];

    if (detectedShort === s1Short) {
      // user spoke in L1 -> show ASR in L1Text, translation in L2Text
      L1Text.textContent = transcript;
      L2Text.textContent = translated || '(ë²ˆì—­ ê²°ê³¼ ì—†ìŒ)';
      appendChat('Translator', `${LANG_MAP[targetLangCode]||targetLangCode}`, translated || '(ë²ˆì—­ ì—†ìŒ)');
      // ìë™ ìŒì„± ì¶œë ¥: ë²ˆì—­ -> ëŒ€ìƒ ì–¸ì–´
      speakOut(translated || '', targetLangCode);
    } else if (detectedShort === s2Short) {
      L2Text.textContent = transcript;
      L1Text.textContent = translated || '(ë²ˆì—­ ê²°ê³¼ ì—†ìŒ)';
      appendChat('Translator', `${LANG_MAP[targetLangCode]||targetLangCode}`, translated || '(ë²ˆì—­ ì—†ìŒ)');
      speakOut(translated || '', targetLangCode);
    } else {
      // ê°ì§€ ì–¸ì–´ê°€ L1/L2 ì¤‘ í•˜ë‚˜ê°€ ì•„ë‹Œ ê²½ìš° (ì˜ˆ: ì˜ì–´) -> translate to selected opposite (we used targetLangCode)
      // Put original in a best-fit box: if detected matches neither, we will show original in L1Text and translation in L2Text
      L1Text.textContent = transcript;
      L2Text.textContent = translated || '(ë²ˆì—­ ê²°ê³¼ ì—†ìŒ)';
      appendChat('Translator', `${LANG_MAP[targetLangCode]||targetLangCode}`, translated || '(ë²ˆì—­ ì—†ìŒ)');
      speakOut(translated || '', targetLangCode);
    }

    status.textContent = `ì™„ë£Œ: ì¸ì‹(${detectedLang||'und'}) â€¢ ë²ˆì—­ í›„ ìŒì„± ì¶œë ¥ ì™„ë£Œ`;
  } catch (err) {
    console.error('ì²˜ë¦¬ ì˜¤ë¥˜', err);
    status.textContent = `ì˜¤ë¥˜: ${err.message || err}`;
    appendChat('Error','', err.message || String(err));
  }
}

// ==================== TTS (ë¸Œë¼ìš°ì €) ====================
function speakOut(text, langCode) {
  if (!text) return;
  try {
    window.speechSynthesis.cancel();
    const ut = new SpeechSynthesisUtterance(text);
    ut.lang = ttsLangFor(langCode);
    // ìŒì„± ì„ íƒ(ê°€ëŠ¥í•˜ë©´ ê°™ì€ ì–¸ì–´ ìŒì„± ì‚¬ìš©)
    const voices = window.speechSynthesis.getVoices();
    const match = voices.find(v => v.lang && v.lang.startsWith((langCode || '').substring(0,2)));
    if (match) ut.voice = match;
    ut.onstart = () => { status.textContent = 'ìŒì„± ì¶œë ¥ ì¤‘...'; };
    ut.onend = () => { status.textContent = 'ìŒì„± ì¶œë ¥ ì™„ë£Œ.'; };
    window.speechSynthesis.speak(ut);
  } catch (e) {
    console.error('TTS ì˜¤ë¥˜', e);
  }
}

// ============ ê° ë°•ìŠ¤ì˜ ì¬ìƒ ë²„íŠ¼ =============
btnTTSL1.addEventListener('click', () => {
  const t = L1Text.textContent.trim();
  if (!t) { alert('ì¬ìƒí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'); return; }
  speakOut(t, selectL1.value);
});
btnTTSL2.addEventListener('click', () => {
  const t = L2Text.textContent.trim();
  if (!t) { alert('ì¬ìƒí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'); return; }
  speakOut(t, selectL2.value);
});

</script>
</body>
</html>
