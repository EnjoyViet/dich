<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>ë‹¤êµ­ì–´ AI ì‹¤ì‹œê°„ í†µì—­ (ë¸Œë¼ìš°ì €)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { background:#0b0b0b; color:#e6eef8; font-family:Inter,ui-sans-serif; }
        .card { background: #111214; border-radius:12px; padding:14px; border:1px solid rgba(255,255,255,0.04); }
        .speaker-box { border-radius:12px; padding:12px; min-height:120px; position:relative; }
        .btn { padding:10px 14px; border-radius:999px; font-weight:600; cursor:pointer; }
        .mic-btn { width:160px; height:60px; font-size:18px; border-radius:12px; transition: all 0.3s ease; }
        /* ë…¹ìŒ ì¤‘ ìŠ¤íƒ€ì¼ (Pulse Effect) */
        .listening { 
            background-color: #ef4444; /* Red color when listening */
            box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); 
            animation: pulse 1.5s infinite; 
            transform: scale(1.05);
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
</head>
<body class="p-6 flex justify-center">

    <div class="w-full max-w-2xl space-y-5">
        <div class="card flex gap-4 items-center justify-between">
            <div class="w-1/2">
                <label class="text-sm text-gray-300">ë‚˜ì˜ ì–¸ì–´ (My Language)</label>
                <select id="selectL1" class="w-full mt-2 p-2 rounded bg-[#0f1720] text-white">
                    <option value="ko-KR">í•œêµ­ì–´ (Korean)</option>
                    <option value="vi-VN">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</option>
                    <option value="en-US">ì˜ì–´ (English)</option>
                    <option value="zh-CN">ì¤‘êµ­ì–´ (Chinese)</option>
                    <option value="ja-JP">ì¼ë³¸ì–´ (Japanese)</option>
                </select>
            </div>

            <div class="w-1/2">
                <label class="text-sm text-gray-300">ìƒëŒ€ë°© ì–¸ì–´ (Their Language)</label>
                <select id="selectL2" class="w-full mt-2 p-2 rounded bg-[#0f1720] text-white">
                    <option value="vi-VN">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</option>
                    <option value="ko-KR">í•œêµ­ì–´ (Korean)</option>
                    <option value="en-US">ì˜ì–´ (English)</option>
                    <option value="zh-CN">ì¤‘êµ­ì–´ (Chinese)</option>
                    <option value="ja-JP">ì¼ë³¸ì–´ (Japanese)</option>
                </select>
            </div>
        </div>

        <div class="card">
            <div class="flex items-center justify-between mb-2">
                <div class="text-sm text-blue-300 font-bold">ğŸ™ <span id="labelL1">í•œêµ­ì–´ (Korean)</span> í™”ì</div>
            </div>
            <div class="speaker-box" style="background:#071028; border:1px solid rgba(59,130,246,0.12);">
                <div id="L1Text" class="whitespace-pre-wrap text-white min-h-[80px]">ë²ˆì—­ëœ ìƒëŒ€ë°© ì–¸ì–´ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</div>
                <button id="btnTTSL1" title="ì´ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸°" class="btn absolute right-3 bottom-3 bg-blue-600 text-white disabled:opacity-50" disabled>ğŸ”Š ìŒì„±</button>
            </div>
        </div>

        <div class="card">
            <div class="flex items-center justify-between mb-2">
                <div class="text-sm text-red-300 font-bold">ğŸ™ <span id="labelL2">ë² íŠ¸ë‚¨ì–´ (Vietnamese)</span> í™”ì</div>
            </div>
            <div class="speaker-box" style="background:#120a0c; border:1px solid rgba(239,68,68,0.08);">
                <div id="L2Text" class="whitespace-pre-wrap text-white min-h-[80px]">í•œêµ­ì–´ (Korean)ë¡œ ë²ˆì—­ëœ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</div>
                <button id="btnTTSL2" title="ì´ í…ìŠ¤íŠ¸ë¥¼ ì½ê¸°" class="btn absolute right-3 bottom-3 bg-red-600 text-white disabled:opacity-50" disabled>ğŸ”Š ìŒì„±</button>
            </div>
        </div>

        <div class="flex justify-center">
            <button id="micMain" class="mic-btn bg-blue-600 text-white font-bold disabled:opacity-50">ìŒì„± ì…ë ¥</button>
        </div>

        <div class="card text-sm text-gray-300">
            <div id="status">ì¤€ë¹„ ì™„ë£Œ. ë…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ 'ìŒì„± ì…ë ¥' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.</div>
            <div id="chatHistory" class="mt-2 max-h-36 overflow-auto text-xs text-gray-400"></div>
        </div>
        <div class="text-xs text-gray-500">âš ï¸ **ì¤‘ìš”:** ì´ ì½”ë“œëŠ” **Google Speech-to-Text API**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. API Keyì— í•´ë‹¹ ê¶Œí•œì´ í™œì„±í™”ë˜ì–´ ìˆì–´ì•¼ í•˜ë©°, **ë¸Œë¼ìš°ì €ì— í‚¤ë¥¼ ì§ì ‘ ë…¸ì¶œ**í•˜ê³  ìˆìŠµë‹ˆë‹¤.</div>
    </div>

<script>
// ====================================================================================================
// âš ï¸ API KEY ì„¤ì •
// ====================================================================================================
// ì‚¬ìš©ìë‹˜ì˜ í‚¤ë¥¼ ì‚¬ìš©í•˜ë˜, ì´ëŠ” ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©ì´ë©°, ë³´ì•ˆìƒ ìœ„í—˜í•  ìˆ˜ ìˆìŒì„ ì¸ì§€í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.
const API_KEY = "AIzaSyD62j5LrOBDu0efSqvKvZ_bOaTu599FqRg--"; // <<--- ì‚¬ìš©ìë‹˜ì˜ API Key
const SPEECH_RECOGNIZE_URL = `https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}`;
const GEMINI_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${API_KEY}`;

// UI elements
const selectL1 = document.getElementById('selectL1');
const selectL2 = document.getElementById('selectL2');
const labelL1 = document.getElementById('labelL1');
const labelL2 = document.getElementById('labelL2');
const L1Text = document.getElementById('L1Text');
const L2Text = document.getElementById('L2Text');
const btnTTSL1 = document.getElementById('btnTTSL1');
const btnTTSL2 = document.getElementById('btnTTSL2');
const micMain = document.getElementById('micMain');
const status = document.getElementById('status');
const chatHistory = document.getElementById('chatHistory');

let mediaRecorder = null;
let recordedChunks = [];
let isRecording = false;
let isProcessing = false;

// ì–¸ì–´ ë§¤í•‘ (ê°„ë‹¨í•œ í‘œì‹œìš©)
const LANG_MAP = {
    'ko-KR': 'í•œêµ­ì–´ (Korean)',
    'vi-VN': 'ë² íŠ¸ë‚¨ì–´ (Vietnamese)',
    'en-US': 'ì˜ì–´ (English)',
    'zh-CN': 'ì¤‘êµ­ì–´ (Chinese)',
    'ja-JP': 'ì¼ë³¸ì–´ (Japanese)'
};

// Google STTê°€ ìë™ ê°ì§€í•  ëŒ€ìƒ ì–¸ì–´ ì½”ë“œ (ìµœëŒ€ 30ê°œê¹Œì§€ ê°€ëŠ¥í•˜ë‚˜, ì—¬ê¸°ì„œëŠ” 5ê°œë§Œ ì§€ì •)
const AUTO_LANGS = ['ko-KR', 'vi-VN', 'en-US', 'zh-CN', 'ja-JP'];
let conversationHistory = []; // ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ ìœ„í•œ ëŒ€í™” ê¸°ë¡

// ==================== ì´ˆê¸° UI ë° ìƒíƒœ ê´€ë¦¬ ====================

function updateLabels() {
    labelL1.textContent = LANG_MAP[selectL1.value] || selectL1.value;
    labelL2.textContent = LANG_MAP[selectL2.value] || selectL2.value;
}

function updateUI(state) {
    // state: 'ready', 'recording', 'processing'
    const disableAll = isProcessing || isRecording;
    selectL1.disabled = disableAll;
    selectL2.disabled = disableAll;
    btnTTSL1.disabled = L1Text.textContent.trim() === 'ë²ˆì—­ëœ ìƒëŒ€ë°© ì–¸ì–´ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.' || disableAll;
    btnTTSL2.disabled = L2Text.textContent.trim() === 'í•œêµ­ì–´ (Korean)ë¡œ ë²ˆì—­ëœ ìŒì„± ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.' || disableAll;

    micMain.disabled = isProcessing;
    micMain.classList.remove('listening', 'bg-red-600', 'bg-blue-600');

    if (state === 'recording') {
        micMain.textContent = 'ë…¹ìŒ ì¤‘... (ì¢…ë£Œ)';
        micMain.classList.add('listening'); // í„ìŠ¤ íš¨ê³¼
        micMain.style.backgroundColor = '#ef4444'; // ë¹¨ê°„ìƒ‰
    } else if (state === 'processing') {
        micMain.textContent = 'ì²˜ë¦¬ ì¤‘...';
        micMain.style.backgroundColor = '#f59e0b'; // ë…¸ë€ìƒ‰
    } else { // 'ready'
        micMain.textContent = 'ìŒì„± ì…ë ¥ ì‹œì‘';
        micMain.style.backgroundColor = '#3b82f6'; // íŒŒë€ìƒ‰
    }
}

updateLabels();
selectL1.addEventListener('change', updateLabels);
selectL2.addEventListener('change', updateLabels);

// ==================== MediaRecorder ë…¹ìŒ ì œì–´ ====================
async function startRecording() {
    if (!API_KEY || API_KEY.startsWith('AIzaSyD62j5LrOBDu0efSqvKvZ_bOaTu599FqRg')) {
        alert('âš ï¸ API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”. (í…ŒìŠ¤íŠ¸ìš©: í‚¤ë¥¼ ë…¸ì¶œí•˜ëŠ” ê²ƒì€ ë³´ì•ˆìƒ ìœ„í—˜í•©ë‹ˆë‹¤.)');
        return;
    }
    recordedChunks = [];
    isRecording = false;

    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert('ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì‹  ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.');
        return;
    }

    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // NOTE: Google STT REST APIëŠ” LINEAR16 16kHz PCMì„ ê¶Œì¥í•˜ë‚˜, ë¸Œë¼ìš°ì €ê°€ ì œê³µí•˜ëŠ” webm/opusë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=opus' });

        mediaRecorder.ondataavailable = (e) => {
            if (e.data && e.data.size > 0) recordedChunks.push(e.data);
        };

        mediaRecorder.onstart = () => {
            isRecording = true;
            updateUI('recording');
            status.textContent = 'ë…¹ìŒ ì¤‘... ë§í•˜ì„¸ìš”.';
        };

        mediaRecorder.onstop = async () => {
            isRecording = false;
            // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ (ê¶Œí•œ í•´ì œ)
            if (mediaRecorder.stream) {
                mediaRecorder.stream.getTracks().forEach(t => t.stop());
            }
            
            // Blob ìƒì„±
            const blob = new Blob(recordedChunks, { type: recordedChunks[0]?.type || 'audio/webm' });
            await processRecordedAudio(blob);
            updateUI('ready');
        };

        mediaRecorder.start();
    } catch (err) {
        console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', err);
        alert('ë§ˆì´í¬ ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        updateUI('ready');
    }
}

function stopRecording() {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
    }
}

micMain.addEventListener('click', () => {
    if (isProcessing) return;
    
    if (!isRecording) {
        startRecording();
    } else {
        stopRecording();
    }
});

// ==================== ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° API í˜¸ì¶œ ====================

function appendChat(role, lang, text) {
    const time = new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' });
    const t = document.createElement('div');
    const roleStyle = role === 'User (ASR)' ? 'text-blue-400' : 'text-red-400';
    t.className = 'p-1 my-1 border-b border-gray-700';
    t.innerHTML = `<strong class="${roleStyle}">${role} [${LANG_MAP[lang] || lang} ${time}]:</strong> ${text}`;
    chatHistory.prepend(t); // ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ prepend ì‚¬ìš©
    
    // ê¸°ë¡ì´ ë„ˆë¬´ ë§ì•„ì§€ë©´ ì œê±°
    while (chatHistory.children.length > 10) {
        chatHistory.removeChild(chatHistory.lastChild);
    }
}

async function blobToBase64(blob) {
    return new Promise((res, rej) => {
        const reader = new FileReader();
        reader.onloadend = () => res(reader.result.split(',')[1]); // base64 string (without prefix)
        reader.onerror = rej;
        reader.readAsDataURL(blob);
    });
}

// 1. STT: Google Speech-to-Text REST (ìë™ ê°ì§€)
async function recognizeSpeechWithGoogle(base64Audio) {
    const primaryLang = selectL1.value;
    const payload = {
        config: {
            encoding: "WEBM_OPUS",      
            sampleRateHertz: 48000,
            // primaryLangCode: ì´ ì–¸ì–´ë¡œ ìš°ì„  ì¸ì‹í•˜ë˜,
            languageCode: primaryLang,
            // alternativeLanguageCodes: ì—¬ê¸° ìˆëŠ” ì–¸ì–´ë“¤ ì¤‘ì—ì„œ ìë™ ê°ì§€í•˜ì—¬ ì¸ì‹í•©ë‹ˆë‹¤.
            alternativeLanguageCodes: AUTO_LANGS.filter(l => l !== primaryLang), 
            maxAlternatives: 1
        },
        audio: {
            content: base64Audio
        }
    };

    const resp = await fetch(SPEECH_RECOGNIZE_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
    });

    if (!resp.ok) {
        const body = await resp.text();
        throw new Error(`Speech-to-Text ì˜¤ë¥˜! HTTP ${resp.status}: ${body}`);
    }
    const json = await resp.json();
    return json;
}

// 2. Gemini ë²ˆì—­
async function translateWithGemini(text, fromLangCode, targetLangCode) {
    const fromName = LANG_MAP[fromLangCode] || fromLangCode;
    const targetName = LANG_MAP[targetLangCode] || targetLangCode;
    
    // ì‹œìŠ¤í…œ ì§€ì¹¨: ì „ë¬¸ í†µì—­ì‚¬ ì—­í•  ë¶€ì—¬
    const systemPrompt = `You are a professional ${fromName} to ${targetName} simultaneous interpreter. Translate the user's input into natural, contextually appropriate, and polite ${targetName}. Only output the translated text. Do not include any extra commentary, notes, or formatting. Your goal is speed and accuracy for real-time conversation.`;

    // ìµœê·¼ 4ê°œ í„´ë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ì†¡ (ì†ë„ ë° í† í° ì ˆì•½)
    const contents = [
        { role: "user", parts: [{ text: systemPrompt }] },
        ...conversationHistory.slice(-4), 
        { role: "user", parts: [{ text: `Translate this text from ${fromName} to ${targetName} naturally and contextually: "${text}"` }] }
    ];

    const payload = {
        contents: contents,
        config: { temperature: 0.1, topK: 1 } // ë¹ ë¥´ê³  ì •í™•í•œ ë²ˆì—­ì„ ìœ„í•´ ë‚®ì€ Temperature ì„¤ì •
    };

    const resp = await fetch(GEMINI_API_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
    });

    if (!resp.ok) {
        const b = await resp.text();
        throw new Error(`Gemini ì˜¤ë¥˜! HTTP ${resp.status}: ${b}`);
    }
    const rjson = await resp.json();
    const translation = rjson?.candidates?.[0]?.content?.parts?.[0]?.text?.trim();

    if (translation) {
         // ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸: ì›ë¬¸ê³¼ ë²ˆì—­ë³¸ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        conversationHistory.push(
            { role: "user", parts: [{ text: text }] },
            { role: "model", parts: [{ text: translation }] }
        );
    }
    
    return translation || '';
}

// 3. TTS (ë¸Œë¼ìš°ì €)
function speakOut(text, langCode) {
    if (!text) return;
    try {
        window.speechSynthesis.cancel();
        const ut = new SpeechSynthesisUtterance(text);
        ut.lang = langCode;
        
        // ìŒì„± ì„ íƒ (langCodeì˜ ì• ë‘ ê¸€ì ì¼ì¹˜í•˜ëŠ” ìŒì„± ì‚¬ìš©)
        const voices = window.speechSynthesis.getVoices();
        const match = voices.find(v => v.lang && v.lang.startsWith((langCode || '').substring(0,2)));
        if (match) ut.voice = match;

        ut.onstart = () => { status.textContent = 'ìŒì„± ì¶œë ¥ ì¤‘...'; updateUI('processing'); };
        ut.onend = () => { status.textContent = 'ìŒì„± ì¶œë ¥ ì™„ë£Œ.'; updateUI('ready'); };
        ut.onerror = (e) => { console.error('TTS ì˜¤ë¥˜', e); status.textContent = 'TTS ì˜¤ë¥˜ ë°œìƒ. (ë¸Œë¼ìš°ì € ë¬¸ì œ)'; updateUI('ready'); };

        window.speechSynthesis.speak(ut);
    } catch (e) {
        console.error('TTS ì˜¤ë¥˜', e);
        status.textContent = 'TTS ì‹œì‘ ì˜¤ë¥˜. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.';
        updateUI('ready');
    }
}

// 4. ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
async function processRecordedAudio(blob) {
    isProcessing = true;
    updateUI('processing');

    try {
        status.textContent = 'ì˜¤ë””ì˜¤ ì¸ì½”ë”© ì¤‘...';
        const base64 = await blobToBase64(blob);
        status.textContent = 'ìŒì„± ì¸ì‹ ìš”ì²­ ì¤‘... (Google Speech-to-Text)';
        
        const sttResp = await recognizeSpeechWithGoogle(base64);

        let transcript = '';
        let detectedLangCode = null;

        if (sttResp.results && sttResp.results.length) {
            // ì¸ì‹ëœ í…ìŠ¤íŠ¸
            transcript = sttResp.results.map(r => (r.alternatives && r.alternatives[0] && r.alternatives[0].transcript) ? r.alternatives[0].transcript : '').join(' ').trim();
            // ê°ì§€ëœ ì–¸ì–´ ì½”ë“œ (Google STTì˜ ì‘ë‹µì—ì„œ ê°€ì ¸ì˜´)
            detectedLangCode = sttResp.results[0].languageCode || null; 
        }

        if (!transcript) {
            status.textContent = 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
            appendChat('System','', 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ.');
            return;
        }
        
        const originalText = transcript;
        const originalLangCode = detectedLangCode || selectL1.value; // ê°ì§€ ì‹¤íŒ¨ ì‹œ L1ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        const originalLangName = LANG_MAP[originalLangCode] || originalLangCode;
        
        appendChat('User (ASR)', originalLangCode, originalText);
        status.textContent = `ê°ì§€ëœ ì–¸ì–´: ${originalLangName}. ë²ˆì—­ ì¤‘...`;

        // ë²ˆì—­ ë°©í–¥ ê²°ì •: ê°ì§€ëœ ì–¸ì–´ê°€ L1ì´ë©´ L2ë¡œ, ê°ì§€ëœ ì–¸ì–´ê°€ L2ì´ë©´ L1ë¡œ ë²ˆì—­
        const selL1 = selectL1.value;
        const selL2 = selectL2.value;
        let targetLangCode;
        let originalBox; // ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•  ë°•ìŠ¤
        let translatedBox; // ë²ˆì—­ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•  ë°•ìŠ¤

        if (originalLangCode.startsWith(selL1.substring(0, 2))) { // L1ìœ¼ë¡œ ê°ì§€ëœ ê²½ìš° (ë˜ëŠ” ê°ì§€ ì‹¤íŒ¨ ì‹œ)
            targetLangCode = selL2;
            originalBox = L1Text;
            translatedBox = L2Text;
        } else if (originalLangCode.startsWith(selL2.substring(0, 2))) { // L2ë¡œ ê°ì§€ëœ ê²½ìš°
            targetLangCode = selL1;
            originalBox = L2Text;
            translatedBox = L1Text;
        } else {
             // L1/L2 ì™¸ì˜ ì œ3ì˜ ì–¸ì–´ê°€ ê°ì§€ëœ ê²½ìš°: L1 ë°•ìŠ¤ì— ì›ë¬¸ í‘œì‹œ, L2 ì–¸ì–´ë¡œ ë²ˆì—­
            targetLangCode = selL2; 
            originalBox = L1Text;
            translatedBox = L2Text;
        }
        
        // ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë°•ìŠ¤ì— ì¦‰ì‹œ í‘œì‹œ
        originalBox.textContent = `[${originalLangName}]: ${originalText}`;
        translatedBox.textContent = `[ë²ˆì—­ ì¤‘]: ${LANG_MAP[targetLangCode] || targetLangCode}ë¡œ í†µì—­...`;


        // Gemini API í˜¸ì¶œ
        const translatedText = await translateWithGemini(originalText, originalLangCode, targetLangCode);

        // UI ì—…ë°ì´íŠ¸
        translatedBox.textContent = `[${LANG_MAP[targetLangCode] || targetLangCode}]: ${translatedText || '(ë²ˆì—­ ê²°ê³¼ ì—†ìŒ)'}`;
        
        appendChat('Translator', targetLangCode, translatedText || '(ë²ˆì—­ ì—†ìŒ)');
        
        // ìë™ ìŒì„± ì¶œë ¥
        if (translatedText) {
            speakOut(translatedText, targetLangCode);
        } else {
             status.textContent = `ì™„ë£Œ: ì¸ì‹(${originalLangName}) â€¢ ë²ˆì—­ ì‹¤íŒ¨`;
             updateUI('ready');
        }

    } catch (err) {
        console.error('ì²˜ë¦¬ ì˜¤ë¥˜:', err);
        status.textContent = `ì˜¤ë¥˜: ${err.message || err}. API Key/ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.`;
        appendChat('Error','', err.message || String(err));
    } finally {
        isProcessing = false;
        if (!window.speechSynthesis.speaking) {
            updateUI('ready');
        }
    }
}

// ============ ê° ë°•ìŠ¤ì˜ ì¬ìƒ ë²„íŠ¼ =============
btnTTSL1.addEventListener('click', () => {
    const t = L1Text.textContent.replace(/^\[.*?\]:\s*/, '').trim(); // [ì–¸ì–´] ì œê±°
    if (!t) { alert('ì¬ìƒí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'); return; }
    speakOut(t, selectL1.value);
});
btnTTSL2.addEventListener('click', () => {
    const t = L2Text.textContent.replace(/^\[.*?\]:\s*/, '').trim(); // [ì–¸ì–´] ì œê±°
    if (!t) { alert('ì¬ìƒí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'); return; }
    speakOut(t, selectL2.value);
});

// ì´ˆê¸°í™” ì‹œ ìŒì„± ëª©ë¡ ë¡œë“œ
window.onload = () => {
    updateLabels();
    updateUI('ready');
};

</script>
</body>
</html>
